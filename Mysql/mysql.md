# 数据库隔离级别
## 1 事务
事务是一些操作的集合，用专业术语讲，它是一个程序的执行单元。事务本身并不包含这4个特性，我们需要通过一些手段，尽可能的让执行单元满足这4个特性。
那么我们就可以称它为事务，或者说是一个正确的事务，完美的事务。

## 2 四大特性ACID
- 原子性：满足原子操作单元。要么全部成功，要么全部失败。
- 一致性：事务的开始和完成，数据都必须保持一致。
- 持久性：数据的修改是永久的。
- 隔离性：事务之间是相互独立的，中间状态对外不可见。

## 3 隔离级别
### 3.1 并发情况下事务引发的问题
一般情况下，多个操作单元并发执行，会出现这么几个问题  
- 脏读：A事务还没提交，B事务就读到了A事务的结果。（破坏了隔离性）
- 不可重复读：A事务在本次事务中，对自己未操作的数据，进行了多次读取，结果出现了不一致或不存在的情况。（破坏了一致性，update和delete）
- 幻读：A事务在本次事务中，对自己未操作的数据，进行了多次读取，第一次读时，数据不存在，第二次读时，数据出现了。（破坏了一致性，insert情况）

### 3.2 引发问题的解决
为了权衡隔离和并发的矛盾，ISO定义了四个事务的隔离级别，每个级别的隔离程度不同，出现的副作用也不同。
- 读未提交（read-uncommitted）: 最低级别，只能保证持久性 
- 读提交 （read-committed）: 语句级别
- 可重复读（repeatable-read）: 事务级别
- 串行化（serializable）: 最高级别，事务与事务完全串行化执行，毫无并发可言，性能极低。  

| 级别 | 脏读 | 不可重复读 | 幻读 |  
| :---: | :---: | :---: | :---: |  
|Read uncommitted|	√|	√|	√|
|Read committed|	×|	√|	√|
|Repeatable read|	×|	×|	√|
|Serializable|	×|	×|	×|

### 3.3 实现（InnoDB）
- 锁机制：当一个事务在执行的时候，阻止其他事务对该事务进行操作。各个隔离级别主要体现在读取数据时加的锁和释放时机。
  - read-uncommitted: 事务读取时不加锁
  - read-committed: 事务读取时加行级锁（读到才加锁），一旦读完，立刻释放（并不是事务结束）
  - repeatable-read: 事务读取时加行级共享锁，直到事务结束才会释放。
  - serializable: 事务读取时加表级共享锁，直到事务结束才释放。
- MVCC机制：生成一个数据快照，并用这个快照来提供一致性的读取，也称为多版本数据控制。
  - 实际上就是CAS版本控制和读写分离的思想
  - 主要作用于 读提交和可重复读级别


#### 3.3.1 LBCC 基于锁的控制
- 乐观锁、互斥锁
- 意向锁
- 行锁
- 间隙锁
- 行锁+间隙锁
- 插入意向锁
- 自增锁
- 空间索引预测锁


#####  3.3.1.1 表锁与行锁区别
表锁相当于包酒店
行锁相当于包房间

innodb中，只有利用索引的更新删除操作，才使用行级锁。           

- 锁定粒度： 表锁>行锁   
- 加锁效率： 表锁>行锁   
- 冲突概率： 表锁>行锁   
- 并发性能： 表锁<行锁  

##### 3.3.1.2 shared locks(行锁) 共享锁，读锁
对某个资源加共享锁，自身可以读该资源，其他人也可以读资源，但无法修改。要想修改需要等共享锁释放后。

加锁： select * from table **lock in share mode**;  
释放锁： commit\rollback;

##### 3.3.1.3 Exclusive locks（行锁） 排它锁
对某个资源加排它锁，自身可以进行增删改查，其他人无法进行任何操作。  
排它锁不能和其他锁共存。  

在任何数据上，只要你加了排它锁，别人都玩不了的。  

加锁： select * from table where id = 1 **for update**;  

释放锁：commit,rollback;
 

##### 3.3.1.4 Intention locks 意向锁
均为表锁，无法手动创建
- 意向共享锁
- 意向排它锁

###### 为什么要加入意向锁？
意向锁不是用来锁定数据的，而是告诉事务，当前已经有个人在占坑了。  
这样就不用一行一行扫描来确定有没有共享锁，有没有排它锁。  
而是直接看表的状态上有没有意向锁来判断我能不能创建一个表锁。  
说白了就是为了提高加表锁的效率

##### 3.3.1.5 自增锁
既满足加锁，又满足高并发的行为。  
级别有 0，1，2  
当innodb_autoinc_lock_mode=2时，效率是最高的。
默认用的是1
0 是表锁，满足123456递增的特性

##### 3.3.1.6 悲观锁
总是假设自己去拿数据的时候别人会修改。所以每次去拿数据的时候都会上锁。这样别人想拿这个数据之前就会阻塞直到它拿到锁。                                           
即：操作之前先上锁。
- 行锁
- 表锁
- 读锁
- 写锁                         

##### 3.3.1.7 乐观锁
总是假设自己拿数据的时候，别人不会去修改，所以不会加锁，但是在更新的时候会判断一下在此期间别人有没有更新数据。             
乐观锁适合读多写少的情况。               

###### 乐观锁的实现
- 版本号机制                 
    在数据表中加一个version字段，表示被修改次数。 当数据被修改时数值+1，当线程A更新数据时，会读取version值，在提交更新时，会再次比较下
    version值一样才更新，否则重试，直到成功。
- CAS算法 也叫非阻塞同步                 
    compare and swap            
    涉及三个参数
    需要读写的内存V                
    进行比较的值A
    拟写入的值B      
    当且仅当A的值等于V时，CAS使用原子操作更新V的值为B。 一般会不断自旋，即不断重试。                  

###### 乐观锁缺点
- ABA问题             
    A修改过程中，B修改了值后又改回原值，CAS就会误以为是原值。            
    可以加入version解决。 
- 自旋开销大，一直重试。                     
    可以设置退出时间解决                           
- 只能保证单个变量               
    

#### 3.3.2 锁算法
##### 3.3.2.1 Record locks 记录锁
等值查询，精准命中就会使用记录锁
通过主键去查询某条记录，用的就是记录锁。

##### 3.3.2.2 Gap locks 间隙锁
开区间如（-∞，1）（1，5）（5，9）（9，11）（11，∞）  
间隙锁只存在于可重复读级别
间隙锁不排它，即在间隙锁的时候，我在某个记录上加排它锁，是成功的，即使这个记录不存在。


##### 3.3.2.3 Next-key locks 临键锁
就是间隙锁+记录锁
右闭区间，如（-∞，1]（1，5]（5，9]（9，11]（11，∞）

当查询区间正好在如 大于5小于9的时候，开启临键锁。


#### 3.3.3 MVCC
MVCC主要是为了提高并发的读写性能，不用加锁就能让多个事务并发。
相当于在开启某个事务的时候，对当前数据库里的数据拍个快照，一致性视图read-view。


innodb在begin事务时，会分配一个事务ID给事务，叫transaction_id，严格递增。  
如 1 age = 12    
事务A修改age=18，它会把事务的transaction_id赋值给这个版本事务ID，记到row_trx_id中。即 row_trx_id=transaction_id  
拍照拍的是什么？拍的是版本号，或者说是事务ID。


**Innodb+MVCC 一定程度上解决了幻读问题。通过多版本号。**  

##### 当前读
当前事务修改的数据，事务自己认不认？  
认。
这就破坏了快照读，所以叫当前读。  
但是当前读可能会一定程度导致幻读。    

# 索引
## 什么是索引？
索引就是帮助MYSQL高效获取数据的**排好序**的**数据结构**  

## 索引的数据结构
- 二叉树
- 红黑树
- hash表 ：对范围查找不友好。
- B树/B+树

### 二叉树
最坏情况可能造成单链表。  

### 红黑树
大数据量时，树的深度会太高，查找次数也会很多。

### B树
- 叶节点具有相同的深度，叶节点的指针为空
- 所有索引元素不重复
- 节点的数据索引从左到右递增排列  
![Image_text](https://raw.githubusercontent.com/jizengguang/PrepareForInterview/master/Picture/btree.png)


### B+树
- 非叶子节点不存储data，只存储索引，可以放更多索引。
- 叶子节点包含所有索引字段
- 叶子节点用指针连接，提高区间访问性能。 妙啊 

![Image_text](https://raw.githubusercontent.com/jizengguang/PrepareForInterview/master/Picture/b%2Btree.png)



高度为3的一个B+树，可以存2000多万条数据。
每层非叶子节点MySQL设置为可存16kb。每条数据为节点指针8字节+6字节=14字节，因此B+树每层可以有1170个分叉。
每层存1170索引元素，叶子节点中是索引元素和索引元素磁盘地址指针，假设一个占1kb，那么一个叶子节点就可以存16个。
因此，1170*1170*16=2000多万

#### b+树的一些坑
- 在int类型的字段上使用了like语句查询，变成了索引字符串类型。导致全表查询。
- 后缀查询，模糊匹配，B+ 树均不支持。如 like '%xxxx' 或 like '%xxx%'，均会导致全表扫描。            
- 联合索引必须加上左侧列进行查询。              
- <> 和not不使用索引。

### hash索引（非聚集索引） 

（只有memory支持显式创建hash索引）              
基于hash表实现                   
进行精准匹配的时候，才会使用hash索引。           

- hash索引只包含hash值和行指针。         
- 只支持精准匹配，不支持范围查询，模糊查询及排序。                
- 索引选择性比较低的情况就不要建索引了，比如性别只有男女。            


## Innodb数据是怎么存储的？
数据都是存储在磁盘上。
- xxx.frm 存储着表结构等
- xxx.ibd 索引+数据，按照B+组织的索引结构文件  

与B+树不同的是，索引结构文件的存储，叶子节点存储的不再是索引地址，而是数据。

## mylsam数据是怎么存储的？
- xxx.frm 存储表结构等
- xxx.MYI 存储索引
- xxx.MYD 存储数据

## 聚集索引（主键索引）
Innodb的主键索引，就是聚集索引。  
什么是聚集索引，就是索引和数据聚集在一个文件里。  
查找数据只需要从ibd文件中查找。  
所以聚集索引查找效率肯定比非聚集索引高。因为非聚集索引要查两个文件啊。  
### 主键索引和非主键索引查询有什么区别？
主键索引，叶子节点存储的是整行数据。  
非主键索引叶子节点存储的是主键的值，非主键索引也称为二级索引。  
当使用主键查询时，根据主键搜索B+树即可。  
而基于非主键索引查询时，先需要根据非索引主键查询到索引的值，再到主键索引树种搜索一次，这个过程叫回表。   
 
**也就是说非主键索引查询需要多扫描一棵索引树。**


## 非聚集索引
索引和数据分开存储，就是非聚集索引
查找数据需要从MYI文件找了再去MYD中找。


## 为什么Innodb表必须有主键，并且推荐使用整型的自增主键。
因为innodb标文件就是按照B+树组织的。没有主键数据是没办法组织的。  
如果建表的时候你没建，它会自动选一列可以唯一标识的建主键，如果找不到这样的列，就会在表里面默认加一列。


## 覆盖索引
想查的值，在以给出的索引树上，可以直接提供查询结果，不需要回表。也就是说，查询条件的索引已经覆盖了查询请求，称之为覆盖索引。  
覆盖索引可以减少树的搜索次数，显著提高查询性能。  



## 联合索引
### 底层存储结构什么样？
假设，name,age,position组成联合索引。排好序。  
则它们的排列规则为：  
先检查第一个索引，从左到右依次比较，小的在前，大的在后。  
如果第一个索引相同，则检查第二个索引，同样，小的在前，大的在后。  
如果第二个索引也相同，则看第三个。 

### 最左前缀原则
查询从索引的最左列开始。

### 如何安排联合索引里的索引顺序？
- 如果调整索引顺序，可以少维护一个索引，那么这个顺序是需要优先考虑的。


# 慢查询
## 慢查询表现
明显感觉大部分应用功能变慢，等待响应时间较长，系统卡顿。             

## 如何开启慢查询
1. 编辑my.ini文件：             
log-output=FILE  log记录到文件           
slow-query-log=1    开启慢查询           
slow_query_log_file="文件路径"       慢查询文件保存路径   
long_query_time=10          大于10秒就是慢查询              

2. set global slow_query_log=on;

## 慢查询日志中记录了哪些东西？
- 用户名，用户IP，线程号
- 执行花费时间
- 执行获得锁时间
- 获得结果行数
- 扫描数据行数
- SQL执行具体时间
- 具体SQL语句


## 慢查询分析工具
MySQLdumpslow   
Perl mysqldumpslow.pl -s t -t 5 slow文件            
-s order(c,t,l,r,al,ar)         
c 总次数           
t 总时间               
l 锁时间           
r 总数据行              
at/al/ar 平均时间

-t 提前前面多少行作为结果输出。                   

# sql优化的方式
1. 服务器硬件优化。优先考虑是不是硬件不行了？用了很多年的老硬盘升级下SSD？
2. MySQL服务器优化，用了许多年的老MySQL，更新换代了N年了，是不是可以换换了？
3. SQL本身语句查询的优化
    - 如果有关联子查询，改成关联查询。
    - 提升适当冗余来提升查询性能。（反范式化设计，空间换时间）

# 三范式
- 第一范式：             
    - 数据库表中所有字段都只有单一属性
    - 单一属性的列由基本数据类型所构成
    - 设计出来的表是简单的二维表                 

不符合第一范式的：
         
|  id   | name.age  |
|  ----  | ----  |      

符合第一范式的：

|  id   | name  |  age  |
|  ----  | ----  |  ----  |


- 第二范式：
    - 要求表中只有一个业务主键：不能存在非主键列只对部分主键的依赖关系。
 
不符合第二范式的：  
订单ID和商品ID 

|订单ID|订单时间|产品ID|    
|---|---|---|

|产品ID|产品名称|
|---|---|   

符合第二范式的：

|订单ID|订单时间|
|---|---|

|订单-商品中间表|订单ID|产品ID|
|---|---|---|

|产品ID|产品名称|
|---|----|

- 第三范式
    - 每个非主属性既不部分依赖于业务主键也不传递依赖于业务主键。

不符合第三范式的：

|订单ID|订单时间|客户编号|客户名称|
|---|---|---|---|    

想修改客户名称的时候，客户编号也要跟着改，这就存在了部分非主键依赖于其他非主键。        

符合第三范式：

|订单ID|订单时间|客户ID|
|---|---|---|
    
|客户ID|客户名称|    
|---|---|    
    

三范式，减少冗余。           
对新增友好，对删除友好，对修改友好。          
对查询不友好。         


# 一条SQL怎么执行的。
1. 请求到连接器，鉴权，获得权限。
2. 查询缓存是否执行过这条语句，有的话直接返回结果。写多的话不建议使用，因为缓存会频繁更新，得不偿失。
3. 分析器解析语句，语法分析。有语法报错就报。
4. 优化器，有多个索引的时候，决定先使用哪个索引，有关联查询的时候，决定各个表连接顺序。
5. 执行器去执行。先检查下对这个表有没有权限，再去使用引擎提供的接口具体执行SQL语句。


# 什么情况下不会使用索引
- 索引选择性太差                   
- <>或not in                 
- is null会使用索引，is not null  不会使用索引。                 
- where子句跳过左侧索引列，直接查询右侧索引字段。                
- 对索引列进行计算或使用函数。                


# 优化索引
- 什么情况下不会使用索引的情况避免掉
- 删除冗余无效索引          


# 索引重新统计        
analyze table xxx;

# optimize 优化表空间，释放表空间
optimize table xxx;                 
会锁表，一定要在维护期间使用。                         


# 关联查询          
## 嵌套循环关联 NLJ
select tb1.col1, tb2.col2 from tb1,tb2 where tb1.col3=tb2.col3 and tb1.col3=1;              
先在外侧筛选，在tb1中筛选出col3=1的数据。
优化器发现跟语句中与tb2有关联，于是把tb1中查出来的数据，拿到tb2中循环检索。                  
全部检索完毕后，进行合并输出。                     
这里把tb1称为驱动表

# 关联查询优化
1. 外键上加索引
2. 查询条件上加索引。            



# explain执行计划      
- id: select 的编号。如果有多表关联查询，id为1的就是驱动表。   
- select_type: 查询类型
    - simple 简单查询
    - Primary: 在复杂查询中，最外侧的select
    - subquery: 包含在select中的子查询                       
    - derived: 包含在from子句中的子查询
    - union: union中第二个随后的select
    - union result：对前面执行的结果集进行去重。会产生临时表。                
- table: 在哪个表上                  
- partition： 在哪个分区上                 
- type: 关联类型或访问类型，即MySQL决定如何查找表中的行。               
    执行效率排行              
     - system
     - const  主键扫描
     - eq_ref  主键与外键关联查询的时候
     - ref  不使用唯一索引，而是使用普通索引或唯一索引的部分前缀，索引需要和某个值比较。
     - fulltext
     - ref_or_null 检索语句包含null的时候
     - index_merge
     - unique_subquery
     - index_subquery
     - range   范围扫描的时候。              
     - index    只需扫描索引树     
     - all  全表扫描
- rows: 要读取的行数
- filtered: 百分比 预估有百分之多少与前表联合
- extra： 执行计划额外信息
    - distinct 一旦找到了与行匹配的行就不再检索。            
    - using index  只使用索引的部分就能返回数据，不需要再去访问表的中记录。索引覆盖
    - using where  先读取整行，再按where条件检查。
    - using temporary 使用临时表
    - using filesort 文件扫描，效率极差。             
    
 
     
# 分库分表
MySQL瓶颈
- IO瓶颈
    - 磁盘读IO瓶颈，热点数据太多，数据库缓存放不下。每次查询产生大量IO，降低查询速度。 分库或垂直分表
    - 网络IO瓶颈，请求数据太多，网络带宽不够。 分库。
- CPU瓶颈
    - SQL问题。 优化SQL
    - 单表数据过大。 水平分表。


## 分库
按照数据库职责不同，将数据库表拆分到不同MySQL服务器中。                      

## 分表
将一张大表，按照某种规则，分门别类的存储在不同服务器相同数据库相同的表中。           

导致的问题：原来可能一个语句就能查的数据，需要查多次聚合后才能得到想要的数据。

于是，分库分表中间件应运而生。         

|分类|分库|分表|中间层|开源|数据库支持|支持语言|更新频率|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|mycat|支持|支持|是|mysql|任意|暂停更新|
|cobar|支持|不支持|是|MySQL|任意|停止维护|
|oneproxy|支持|支持|是|否|MySQL|任意|官方维护


## 水平分库
以字段为依据，按照一定策略，将一个库中的数据拆分到多个库中。              
结果：
- 每个库机构一样
- 每个库数据不一样，没有交集
- 所有库的全集就是全量数据              

场景：
没有明显业务归属来垂直分库的时候。


## 水平分表
以字段为依据，按照一定策略，将一个表中的数据拆分到多个表中。                  
结果：
- 每个表结构一样
- 每个表数据不一样，没有交集
- 所有表的合集就是全量数据。                                  
场景：             
单表数据量太多，影响SQL效率时。

## 垂直分库
以表为依据，按照不同业务归属不同，将表拆分到不同的库中。
结果：
- 每个库的结构不一样
- 每个库数据不一样，没有交集。
- 所有库的并集是全量数据。

场景：
单独的业务模块单独的数据库，服务化。

## 垂直分表
以字段为依据，按照字段活跃性，将表中字段拆分到不同表中。                
结果：
- 每个表的结构都不一样。
- 每个表的数据也不一样。一般来说每个表至少有一列交集，一般是主键用来关联数据。
- 所有表的并集是全量数据。

垂直分表是为了区分热点数据和非热点数据。热点数据作主表，非热点数据作为拓展表。         


## 分库分表步骤
根据当前容量评估分库分表个数；         
选key；                       
分表规则；           
执行；                 
扩容问题。

## 分库分表问题

1. 非partition key映射问题  基于水平分表，拆分策略常为hash法。         
    1.1 端上除了partition key只有一个非partition key作为条件查询               
      - 映射法        
      - 基因法
    1.2 端上除了partition key不止一个非partition key作为条件查询
      - 映射法
      - 冗余法
    1.3 后台除了partition key还有各种非partition key组合条件查询
      - NOSQL法
      - 冗余法
 
2. 非partition key跨库跨表分页查询问题             
   基于水平分库分表，拆分策略常用hash法。            
   nosql法解决
   
3. 扩容问题  
   - 水平扩容库（升级从库法）
     1. 增加一个VIP，也指向主库。
     2. 数据库配置文件，由两个数据源变4个。
     3. 双VIP改成单VIP
     4. 备库升级，并和第一步添加的VIP关联
     5. 解除旧的主备同步，添加新的主备同步。
     6. 删除冗余数据  
   - 水平扩容表（双写迁移法）
     1. （同步双写）修改应用配置和代码，加上双写，部署
     2. 将老库中的老数据同步到新库中
     3. （同步双写）以老库中的老数据复制到新库中
     4. （同步双写）修改应用配置和代码，去掉双写，部署。


# 主从复制
## 复制的基本原理
MySQL主从复制涉及到三个线程，一个运行在主节点（log dump thread），其余两个(I/O thread, SQL thread)运行在从节点。              

l 主节点 binary log dump 线程当从节点连接主节点时，主节点会创建一个log dump 线程，用于发送bin-log的内容。                  
在读取bin-log中的操作时，此线程会对主节点上的bin-log加锁，当读取完成，甚至在发动给从节点之前，锁会被释放。                    
l 从节点I/O线程当从节点上执行`start slave`命令之后，从节点会创建一个I/O线程用来连接主节点，请求主库中更新的bin-log。                
I/O线程接收到主节点binlog dump 进程发来的更新之后，保存在本地relay-log中。l 从节点SQL线程SQL线程负责读取relay log中的内容，              
解析成具体的操作并执行，最终保证主从数据的一致性。对于每一个主从连接，都需要三个进程来完成。                  
当主节点有多个从节点时，主节点会为每一个当前连接的从节点建一个binary log dump 进程，而每个从节点都有自己的I/O进程，SQL进程。                   
从节点用两个线程将从主库拉取更新和执行分成独立的任务，这样在执行同步数据任务的时候，不会降低读操作的性能。                   
比如，如果从节点没有运行，此时I/O进程可以很快从主节点获取更新，尽管SQL进程还没有执行。如果在SQL进程执行之前从节点服务停止，                  
至少I/O进程已经从主节点拉取到了最新的变更并且保存在本地relay日志中，当服务再次起来之后，就可以完成数据的同步。                 
要实施复制，首先必须打开Master 端的binary log（bin-log）功能，否则无法实现。                  
因为整个复制过程实际上就是Slave 从Master 端获取该日志然后再在自己身上完全顺序的执行日志中所记录的各种操作。                    

## 主从复制模式
- 异步  从节点连接主节点去读binlog。 存在延时，可能会failover。       
- 半同步 主节点只要接收到一台从节点的返回消息，就commit。否则等超时切回异步模式。                   
- 全同步   主节点和所有从节点全部执行commit并确认才会向客户端返回成功。
    - binlog 记录
    - GTID复制模式
        - 在传统的复制里面，当发生故障，需要主从切换，需要找到binlog和pos点，然后将主节点指向新的主节点，相对来说比较麻烦，
            也容易出错。在MySQL 5.6里面，不用再找binlog和pos点，我们只需要知道主节点的ip，端口，以及账号密码就行，
            因为复制是自动的，MySQL会通过内部机制GTID自动找点同步。
        - 多线程复制（基于库），在MySQL 5.6以前的版本，slave的复制是单线程的。一个事件一个事件的读取应用。而master是并发写入的，
        所以延时是避免不了的。唯一有效的方法是把多个库放在多台slave，这样又有点浪费服务器。在MySQL 5.6里面，我们可以把多个表放在多个库，
        这样就可以使用多线程复制。
        
        **基于GTID复制实现的工作原理**             
        主节点更新数据时，会在事务前产生GTID，一起记录到binlog日志中。从节点的I/O线程将变更的bin log，写入到本地的relay log中。
        SQL线程从relay log中获取GTID，然后对比本地binlog是否有记录（所以MySQL从节点必须要开启binary log）。
        如果有记录，说明该GTID的事务已经执行，从节点会忽略。如果没有记录，从节点就会从relay log中执行该GTID的事务，并记录到bin log。
        在解析过程中会判断是否有主键，如果没有就用二级索引，如果有就用全部扫描。   
    
## 主从复制主要用途
- 读写分离
- 数据实时备份
- 高可用HA

## 主从形式
- 一主一从
- 一主多从
- 双主复制
- 多主一从
       

# 读写分离
读写分离与主从复制不分家，都是为了解决高并发问题。               
master写入，从节点读取。             

## 读写分离实现方式
- AOP方式，通过方法名判断读相关的访问从库。                
- 开源中间件         


# sql某列最大记录
使用 order by desc  降序排列?

# left join, inner join

# 判断索引执行顺序


# 火车买票 多区间 设计表



