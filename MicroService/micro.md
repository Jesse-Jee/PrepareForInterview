# 微服务
## 单体应用
应用复杂，可靠性低，敏捷开发和部署不好完成。
基于目前的业务场景，决定做划分。

## 为什么做微服务
SOA（面向服务），微服务就是SOA的一种实践。  

- 单一职责：一个服务只做好一件事。
- 小而美：易维护，易测试。
- 尽早创建原型：尽早提供API，可以给前端小姐姐先mock
- 可移植性高

## 什么是微服务
围绕业务功能构建的，服务关注单一业务，服务间采用轻量级通信机制，可以全自动独立部署，可以使用不同的编程语言和数据存储技术。
实现服务组件化，通过组件组合快速开发系统。

- 原子服务
- 独立进程
- 隔离部署
- 去中心化服务治理

缺点：
基础设施建设，复杂度高。

## 微服务不足
- rpc通讯。需要写代码消除信息传递中速度过慢或者服务不可用等局部失效的问题。
    举例：批量请求的问题，写for循环，导致后面的服务频繁调用，上游for循环10下，到下游可能就被放大100倍。
         如何解决呢？提供粗粒度的batch接口。
- 分区的数据库架构，同时更新多个业务主体的事务很普遍，需要更新不同服务的数据，对开发人员提出了更高的要求。
- 测试复杂
- 服务间的依赖复杂，升级波及多个服务模块修改。
- 运维基础设施挑战大。


## 组件服务化 
- kit:一个微服务的基础库框架（如，go-micro，beego等等）B站kratos  
- service： 业务代码+kit依赖+第三方依赖组成的业务微服务
- rpc + message queue: 轻量级通讯。

## 去中心化
- 数据去中心化：每个服务独占db
- 治理去中心化：热点服务的处理 
- 技术去中心化

## 基础设施自动化
- CICD：gerrit + pipeline + Jenkins
- 测试：测试环境，单元测试，API自动测试
- 在线运行时：k8s，普罗米修斯，ELK等

## 可用性 & 兼容性设计
"所有服务都会炸"的思想  
微服务架构不可避免会出现网络延迟，消息格式，负载，容错等问题。
尽量采用粗粒度的进程间通信  

- 隔离
- 超时控制
- 负载保护
- 限流
- 降级
- 重试
- 负载均衡

接口一定要兼容。发送的数据要保守，最小化传送必要信息。接收时要开放，最大限度容忍冗余数据，保证兼容性。


# 微服务设计
## API Gateway
网页->ngnix->各微服务带来的困难。
- 客户端到微服务直接通信，强耦合
- 需要多次请求，客户端聚合数据，工作量巨大，延迟高。
- 协议不利于统一
- 多终端兼容逻辑复杂
- 统一逻辑无法收敛，比如安全认证，限流

**演化：**
网页-> ngnix -> api-interface -> 各微服务

在api-interface中作为统一的协议出口。
在服务内进行大量的数据集聚合，带来很多优势：
- 轻量交互：协议精简、聚合
- 差异服务：针对终端定制API
- 动态升级：原有系统兼容升级，更新服务而非协议
- 沟通效率
 
api-interface 可以称为是BFF，是一种适配服务。将后端微服务进行适配，向无线端暴露友好和统一的API。

**进一步演化**
将BFF上层，使用API Gateway（Envoy、zuul、kong、ApiSix），将路由，认证，限流，安全，全部上沉，BFF只做聚合。  
网页->API Gateway -> BFF -> 微服务  
4/7层负载均衡使用（ELB/F5/lua）


[什么是envoy](https://www.servicemesher.com/envoy/intro/what_is_envoy.html)


## 微服务划分

- 按部门划分，业务
- 按业务边界
- CQRS 将应用程序分为两部分（命令端和查询端），实际上就是读写分离。


## 微服务安全
通常在API Gateway进行统一的认证拦截，一旦认证成功，会使用JWT方式通过RPC元数据方式传递到BFF层，BFF校验token完整性后把身份信息注入到应用的context中。  

对于服务内部，区分身份认证和授权。  
- full trust
- half trust
- zero trust


# grpc
## rpc概念 

## grpc概念
高性能开源统一RPC框架  
**优势** 
- 多语言
- 轻量级，高性能：序列化支持pb
- 可插拔
- 支持IDL
- 设计理念
- 基于标准的HTTP2设计，支持双向流，消息头压缩，单TCP多路复用，服务端推送等。
- 服务而非对象，消息而非引用。
- 负载无关
- 支持流
- 阻塞式和非阻塞式
- 元数据交换
- 保准化状态码

## HealthCheck
用于检查服务提供者健康，以便异常时被摘除，或恢复后重新加入。      
也可用于平滑发布        

## grpc性能优化


## 微服务的数据库数据一致性问题
基本上都是通过 **本地事务+消息队列** 解决一致性问题。
 
# 服务发现
## 客户端发现方式 
服务实例启动时，网络地址会注册到注册表中，实例终止时，再从注册表中删除。这个服务实例的注册表通过心跳动态刷新。客户端使用负载均衡算法，
去选择一个可用的服务实例去请求。        
## 服务端发现
客户端通过负载均衡器向一个服务发送请求，这个负载均衡器会查询服务注册表，并将请求路由到可用服务实例上。服务实例在服务注册表上被注册和注销。           




# 微服务治理

# 服务平滑升级流程
1. 收到一个kill信号
2. 向服务注册中心发送一个注销请求，把自己注销
3. 把自己的HealthCheck标记为失败。
4. 使用grpc或HTTP shutdown接口
5. 如果发现两个心跳周期容器还退不出，就kill -9 强制退出。
6. 新的服务初始化好了，向注册中心注册，HealthCheck恢复正常。服务升级上线完成。

# 链路追踪

# protobuf 协议

# rpc概念

# 负载均衡 LB(LoadBalance)
通过负载均衡将用户的请求分发到不同的服务器用来提高网站、应用、数据库或其他服务的性能以及可靠性。    
## 技术分类
- 服务器负载均衡：实现服务器的动态选择
- 链路负载均衡： 实现链路的动态选择
- 防火墙负载均衡：实现多防火墙设备的动态选择。
## 按七层模型分类
主要在应用层、传输层、网络层和数据链路层做文章。        

**二层负载**
负载均衡服务器对外提供一个虚IP（VIP），集群中的不同机器采用相同的IP地址，但是机器MAC地址不同。当负载均衡服务器接收到请求后，通过改下请求中
目标Mac地址的方式，将请求转发到目标机器上实现负载均衡。（LVS的DR模式）         
**三层负载**
与二层相似，负载均衡服务器对外依然提供一个VIP，集群中的不同机器采用不同的IP地址。当负载均衡服务器接收到请求后，根据不同的负载均衡算法，
通过IP转发到不同服务器上。          
**四层负载**
四层负载工作在传输层，传输层只有TCP UDP协议，四层负载均衡服务器接收到用户请求后，修改数据包中的地址信息（IP+端口号）将流量转发到应用服务器。            
**七层负载**    
七层负载工作在应用层，协议较多，HTTP，dns等等。这一层协议多，可基于这些协议来负载。       

## 负载均衡工具
- Nginx 主要用作七层负载
    - 是一个网页服务器，可以反向代理HTTP，HTTPS，SMTP，IMAP，POP3的协议链接，以及一个负载均衡器和一个HTTP缓存。         
- LVS 主要用作四层负载
    - Linux Virtual Server（Linux虚拟服务器）    
- HAProxy 主要用作七层负载，也可做四层负载

## 负载均衡算法
- 轮询
- 加权轮询
- 最少连接
- 加权最少连接
- 随机
- 加权随机
- 源地址散列
- 源地址端口散列

 
# CAP原则
- Consistency 一致性  所有数据同一时刻是否有同样的值
- Availablity 可用性   一部分节点异常，剩余集群是否能提供服务     
- Partition tolerance 分区容错性  系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择。

CAP原则指的是三个原则最多同时实现两点，三者不可兼顾。        

阿里的一个开源服务发现中心。
![nacos](https://nacos.io/zh-cn/docs/what-is-nacos.html)





