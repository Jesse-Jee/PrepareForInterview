# Redis支持的数据类型及底层原理
- string
    - SDS 简单动态字符串
- list
    - 双向链表
    - zipList压缩列表
- hash
    - 哈希表
    - 压缩列表
- set
    - 哈希表
    - 整数数组
- sorted set（zset）
    - 压缩列表
    - 跳表
    
拓展的话，还有：
- bitmap 用于二值统计，非0即1的场景，如签到
- Hyperloglog 用于统计基数
- GEO 基于位置信息服务的应用，附近的餐馆等。

压缩列表的结构：                

|zlbytes列表长度|zltail列表尾偏移量|zllen列表entry个数|entry1|...|entryN|zlend列表结束|
|---|---|---|---|---|---|---|

entry结构


|prev_len前一个entry长度，小于254字节就是1字节，大于就是5字节|encoding编码方式1字节|len自身长度4字节|content实际数据|
|---|---|---|---|




## string
### 使用
set key value  
get key  
mset key1 value1 key2 value2  
mget key1 key2  
INCR key 递增数字  
INCRBY key increment 递增指定数字  
DECR key 递减数字   
DECRBY key increment 递减指定数字  
strlen key 获取字符串长度

### 底层结构
SDS simple dynamic string

|len(4B)|
|:---:|  
|alloc(4B)|
|buf("redis\0")|       

- buf 字节数组，保存数据，为了表示结束，会在数组后面加"\0",会额外占1个字节的开销。
- len 4字节，表示buf实际长度
- alloc 4字节，表示实际分配长度，一般大于len。


### 分布式锁
setnx key value   
set key value [EX seconds][PX milliseconds][NX|XX]  
**EX**:key 存在多少秒后过期     
**PX**：key在多少毫秒后过期                      
**NX**：当key不存在是才能创建key 效果等同于setnx                   
**XX**：当key存在是覆盖key

实例化场景：              
Redis开发者提出分布式锁RedLock算法          


### 应用场景
- 商品编号、订单号采用INCR生成
- 点赞数之类的

## hash
### 使用
Hset key filed value  
hget key filed  
hmset key filed1 value1 filed2 value2  
hmget key filed1[filed...]  
hgetall key  
hlen  
hdel  

### 应用场景
购物车

## list
### 使用
LPUSH key value
RPUSH key value
LRANGE key start stop
LLEN key

### 应用场景
微信文章订阅公众号：公众号发布的新文章，将其ID放到我这个关注者的list中来。

## set
### 使用
SADD key member  
SREM key member  删除
SMEMBERS key  获取集合中所有元素  
SISMEMBERS key member  判断元素是否在集合中     
SCARD key  集合中元素个数  
SRANDMEMBER key [数字] 从集合中随机弹出一个元素，不删除    
SPOP key 从集合中随机弹出一个元素，删除。  

### 集合运算
- 差集 SDIFF key
- 交集 SINTER key
- 并集 SUNION key  


### 应用场景
- 微信抽奖小程序 SRANDMEMBER 如果不重复获奖，用SPOP
- 朋友圈点赞 
- 微博好友关注，共同关注的人，我关注的人也关注了他
- 推可能认识的人

## zset
### 使用
ZADD key score member  
ZRANGE key start stop 从小到大排序  
ZSCORE key member  获取元素分数  
ZREM key member  删除元素  
ZRANGEBYSCORE key min max 获取指定范围元素    
ZINCRBY key increment member 增加某个元素分数  
ZCARD key  获取集合中元素数量  
ZCOUNT key min max指定分数范围内的元素个数  

### 应用场景
- 热销
- 打赏排行  



# Redis内存淘汰策略
执行内存淘汰策略前，要先经过删除策略。

## Redis过期键删除策略
- 定时删除：立即删除能保证内存新鲜度，因为它能在键一过期立马删除，占用的内存也会随之释放。
    - 但是，对CPU不友好，因为删除会占CPU时间。实时删除，会让CPU性能损耗，影响数据的读取操作。
- 惰性删除：数据到达过期时间，不处理。等下次访问该数据时，如果没过期，返回数据，如果过期了，删除。
    - 但是，对内存不友好。万一这个数据后面不被访问了呢？一直占用着内存。
- 定期删除：每隔一段时间执行一次删除过期键的策略。并通过限制删除操作执行的时长和频率来减少删除操作对CPU的影响。
    - 周期性轮询时效性数据，采用随机抽取策略，利用过期数据占比的方式控制删除额度。
        - 检测频度可自定义设置
        - 长期占用内存的冷数据会被清除。
    - 难点：确定删除操作执行的时长和频率。太频繁的话CPU一样要崩溃。执行不频繁的话，和惰性一样，还是会导致数据不能及时删掉。
    
**上述三种都有漏洞，必须有兜底的策略。**     


## 8种缓存淘汰策略
在redis.conf中设置的。
默认为不驱逐

- 不驱逐：默认，存满返回错误。我存满了，不干了。
- allkeys-lru：对所有keys使用lru算法删除
- volatile-lru：对所有设置了过期时间的key使用LRU算法删除。
- allkeys-random：对所有key进行随机删除
- volatile-random：对所有设置了过期时间的key随机删除。
- volatile-TTL：删除马上过期的key
- allkeys-lfu：对所有key使用lfu算法删除。
- volatile-lfu：对所有设置过期时间的key使用lfu算法删除。

LRU：最近最少使用
LFU：最近最少频率使用

## 淘汰策略总结
- 两个维度
    - 过期的中选
    - 所有的里面选
- 四个方面
    - LRU
    - LFU
    - random
    - TTL
    
## 你平时用哪一种
allkeys-lru

### 如何配置，如何修改？
- redis.conf文件中设置 maxmemory-policy allkeys-lru
- config set maxmemory-policy allkeys-lru

# zset时间复杂度
zset的底层是什么实现的？
压缩列表和跳表。
跳表是什么呢？
链表加多级索引，就是跳表。
跳表的查询，时间复杂度是O(logN)
插入和删除，时间复杂度也为O(logN)


# 缓存和数据库间的一致性问题

## 缓存的类型
- 只读缓存：
    - 应用要读取数据时，调用Redis get接口。  
    - 应用要写数据时，会直接发往数据库，在数据库中增删改。  
    - 对于要删改的数据，如果Redis已经缓存，需要先把缓存删除，Redis中就没有这些数据了。  
    当下次查询时，发生缓存缺失，应用会把数据从数据库读取出来，写入到缓存中。  
    - 数据不会有丢失风险
    
- 读写缓存：
    - 在缓存中直接对数据进行增删改
    - 最新数据在Redis中，万一宕机，会发生数据丢失。
    - 策略：
        - 同步直写：缓存写完了，也要等数据库写完才返回，增加响应延迟。
        - 异步写回：写操作先在缓存处理，等到要被从内存中淘汰出来的时候，缓存将他们写回后端数据库。万一掉电，会丢失。

## 什么是一致性？
- 缓存中有数据，必须与数据库中值一致
- 缓存中无数据，数据库中必须是最新值

## 数据不一致是如何发生的？
- 读写缓存下：
    - 同步写回策略：在业务应用中使用事务，保证数据库更新和缓存更新的原子性，要么同成功，要么同失败。
    - 异步写回策略：如果对数据一致性要求不高，如电商产品非关键属性。
- 只读缓存下：
    - 新增、删除、修改都直接操作数据库，如果缓存中有，先删除缓存。下次查询时，发生缓存缺失，再更新到Redis缓存中。

不符合一致性的，就是数据不一致了。
只读模式下删改数据时：
    应用既要更新数据库，又要删除缓存数据。这两个操作如果无法保证原子性，就会出现数据不一致。
    - 先删缓存，再改数据库的情况。如果缓存删除成功，数据更新失败，那么应用访问数据时，缓存中没有数据，发送缓存缺失，从数据库中获取的还是旧值。
    - 先改数据库，再删缓存。如果改数据库成功了，删缓存失败了。数据又不一致。  

## 如何保证数据一致性
   重试机制  
    把要删除或更新的数据，暂存在消息队列，当应用没能成功删除或更新时，可以从消息队列中重新拿到这些值，然后再次删除或更新。超过一定的重试次数就报错。
    假设在大量并发请求的情况下，还是有可能发生不一致的问题。  
    如：  
   - 情况一、先删缓存，再更新数据库  
    线程A删除缓存后，还没来得及更新数据库，线程B就来读取缓存，发生缓存缺失，就会去数据库读。这时带来两个问题。
        - 线程B读取到数据库旧值
        - 线程B从数据库读取到旧值后，把旧值写入缓存，其他线程会从缓存读取到旧值。
    等线程A再写入到数据库中后，出现了缓存与数据库值不一致情况。  
        - **解决**（延迟双删策略）
         线程A更新完数据库后，先sleep一会，再执行一遍缓存删除操作。sleep时间统计下实际线程读数据和写缓存的时间作为基础。
         
   - 情况二、先更新数据库值，再删除缓存值
    线程A删除了数据库中的值，还没来得及删缓存中的，线程B从缓存中读取数据。
    这种情况如果并发请求不是很多，一般缓存删除是很快的。这种情况对业务影响较小。     
![Image_text](https://raw.githubusercontent.com/jizengguang/PrepareForInterview/master/Picture/redis_data_con.png)

**优先使用先更新数据库，再删除缓存的方式**
- 先删缓存，再更新数据库的话，有可能导致请求因访问缺失而访问数据库，增加数据库压力。
- 延迟双删策略的sleep时间不好确定。

# 缓存雪崩，缓存穿透，缓存击穿
## 缓存雪崩
**大量应用请求无法在Redis缓存中进行处理，紧接着大量请求发送到数据库，导致数据库压力剧增。**
- 缓存中有大量数据同时过期，导致大量请求无法得到处理。  
    当数据保存在缓存中，并且设置了过期时间时，如果在某一个时刻，大量数据同时过期，此时，应用再访问这些数据的话，就会发生缓存缺失。
    紧接着，应用就会把请求发送给数据库，从数据库中读取数据。如果应用的并发请求量很大，那么数据库的压力也就很大，
    这会进一步影响到数据库的其他正常业务请求处理。
    - 避免设置相同的过期时间，设置过期时间时，加个较小的随机数。
    - 服务降级：针对不同的数据采取不同的处理方式。
        - 当业务查询的是非核心数据，暂时停止从缓存中查询这些数据，直接返回预定义的或者空值。
        - 如果查询的是核心数据，可以继续查询。
- Redis实例宕机
    - 业务系统实现熔断或限流
      - 熔断
      就是业务应用调用缓存接口时，缓存客户端并不把请求发给 Redis 缓存实例，而是直接返回，
      等到 Redis 缓存实例重新恢复服务后，再允许应用请求发送到缓存系统。  
      通过监控检测Redis宕机后，启动服务熔断机制。这种对业务影响较大
      - 限流
      请求入口前端控制每秒进入系统的请求数。
   - 事前预防
## 缓存击穿
**针对某个访问非常频繁的热点数据请求，无法在缓存中进行处理，紧接着，访问该数据的大量请求，一下子发送到了数据库。数据库压力剧增**    
一般发生在热点数据过期失效时。  
解决办法：访问频繁的热点数据，不设置过期时间。

## 缓存穿透
**要访问的数据既不在Redis缓存中，也不在数据库中。**
这就导致请求访问Redis时发现缓存缺失，再去访问数据库，发现也没有要访问的数据。应用就无法从数据库中读取数据再写入缓存。如果应用有大量并发读请求，
就会给缓存和数据库增加大量压力。    
**发生场景：**  
- 业务层误操作，把缓存和数据库中数据误删。
- 恶意攻击，专门访问数据库中没有的数据。   
 
**应对方案：**  
 - 缓存空值或缺省值
 - 使用布隆过滤器先判断，布隆过滤器可以使用Redis实现。
 - 前端进行请求合法性检测

以上雪崩，击穿，穿透。最好是采取预防性措施：
- 针对缓存雪崩，合理地设置数据过期时间，以及搭建高可靠缓存集群；
- 针对缓存击穿，在缓存访问非常频繁的热点数据时，不要设置过期时间；
- 针对缓存穿透，提前在入口前端实现恶意请求检测，或者规范数据库的数据删除操作，避免误删除。  


# Redis线程模型
## Redis为什么快？
- 内存，采用了高效的数据结构
- 多路复用机制，

6.0之前的版本都是单线程异步处理IO
这里的单线程，主要指的是网络IO和键值读写是由一个线程完成的。但其他功能如持久化，异步删除，集群数据同步等，都是额外线程做的。
Redis处理请求要经过几步：
1. 接收：通过TCP接收到命令，可能经过多次TCP，ACK，IO操作
2. 解析：将命令取出来
3. 执行：到对应地方把value读出来
4. 返回：把value通过TCP返回给客户端。

网络IO处理：
- bind()
- listen()
- accept()
- recv()
- parse()

键值读写：
- get  

网络IO回复：
- send()


可能会阻塞在 accept()
但是socket模型支持非阻塞模式。  

**基于多路复用的高性能IO模型**
一个线程处理多个IO流，select/epoll机制。
该机制允许内核中，同时存在多个监听套接字和已连接套接字。
select/epoll 提供了基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数。  
select/epoll 一旦监测到 FD 上有请求到达时，就会触发相应的事件。这些事件会被放进一个事件队列，Redis 单线程对该事件队列不断进行处理。

单线程模型的瓶颈
- 大value拉胯
- QOS无法更上一层楼

Redis主线程的时间消耗主要是：
- 逻辑计算
- 同步IO读写，拷贝数据导致的消耗

当value比较大时，瓶颈首先会出现在同步IO上，主要消耗在：
- 从socket中读取请求数据，会从内核态将数据拷贝到用户态（read调用）
- 将数据回写到socket，会将数据从用户态拷贝到内核态（write调用）

这部分读写占用了CPU大量时间，这也是Redis引入多线程IO的目的。


**多线程IO：**
- 用一组单独的线程专门进行 read/write socket读写调用 （同步IO）
- 读回调函数中不再读数据，而是将对应的连接追加到可读clients_pending_read的链表
- 主线程在beforeSleep中将IO读任务分给IO线程组
- 主线程自己也处理一个IO读任务，并自旋式等IO线程组处理完，再继续往下
- 主线程在beforeSleep中将IO写任务分给IO线程组
- 主线程自己也处理一个IO写任务，并自旋式等IO线程组处理完，再继续往下
- IO线程组要么同时在读，要么同时在写
- 命令的执行由主线程串行执行(保持单线程)
- IO线程数量可配置



# Redis键值用什么结构组织？
Redis使用hash表来保存所有键值对。  
一个哈希表，其实就是一个数组，数组中的每个元素，是一个哈希桶。哈希桶中的元素保存的不是具体的值，而是指向具体值的指针。   
哈希桶的entry元素中保存的了*key 和*value，分别指向了实际的键和值。  
优势是：可以在O(1)de时间复杂度找到键值对。  
 
![Image_text](https://raw.githubusercontent.com/jizengguang/PrepareForInterview/master/Picture/hash_bucket.png)

## hash冲突
拉链法：  
同一个哈希桶中的多个元素使用一个链表保存，它们之间依次用指针连接。  

拉链法造成了一个问题，当冲突链上的元素越来越多的时候，查找耗时就增加。于是就引出rehash操作。  
## rehash 也就是扩容
Redis采用的是渐进式rehash
rehash：增加哈希桶数量，让逐渐增多的entry元素在更多的桶里分散保存。

Redis默认使用了两张全局hash表，当开始插入数据时，默认使用哈希表1，此时hash表2并没有被分配空间，当数据增多，Redis开始执行rehash。

### rehash过程
1. 给hash表2分配空间，一般树hash表1的两倍。  
2. 索引计数器变量rehashidx设置为0，表示开始rehash，Redis继续正常处理客户端请求，每处理一个请求时，从hash表1的第一个索引位置开始，
顺带着这个索引位置上的所有entries拷贝到哈希表2中，将rehashidx增加1。等处理下一个请求时，继续处理下一个索引位置的entries。直到全部迁移完成，
rehashidx设置为-1。
3. 释放hash表1的空间，留待下次扩容使用。

这样可以避免一次性大量数据拷贝，保证了数据的快速访问。  

### rehash的触发条件是？
每次put的时候检查是否需要。
1. 当前不是在进行bgsave,也没有在bgrewriteaof,并且hash负载因子大于1。
2. 放弃正在执行bgsave，bgrewriteaod,并且hash负载因子大于等于5；

负载因子超过5，不管你在干嘛，都得给我开始rehash扩容。

### 什么时候缩容？
Redis定时任务检查。  
当前hash表保存的key数量与hash表大小比例小于10%的时候。




# 持久化比较
## AOF （Append only file）
AOF是写后日志，Redis先执行命令，数据写入内存，然后才记录下日志。  
AOF中记录的是Redis收到的每条命令。

*3     //当前命令有三部分    
$3     //命令的字节数，set
set
$7     //testkey字节数 
testkey  
$9  
testvalue  

因为Redis不会对命令进行语法检查，因此，写后日志的方式：
- 可以避免记录错误命令的情况。  
- 不会阻塞当前的操作。

### 风险
- 刚执行完命令还没来得及记录日志，就宕机了。
- AOF虽然不会阻塞当前的命令的操作，但是对下一个操作可能带来阻塞风险。如写日志很慢的情况。

### AOF写回策略
- Always：同步写回，命令执行完就写。  
    - 基本不丢数据，但影响主线程性能。
- Everysec：每秒写回。命令操作完成后，日志先写到AOF文件的内存缓冲区，每隔一秒把缓存区内容写入磁盘。  
    - 折中方案。丢失数据少，性能影响小。
- NO：写到缓存区，操作系统决定什么时候写回。  
    - 宕机会丢失数据

### AOF重写机制
AOF日志文件过大了，会影响性能，恢复起来也慢。  
根据数据库的现状创建一个新的AOF文件。即：读取当前数据库中所有键值对，对每个键值对用一条命令记录它的写入。  

这样可以实现多条操作命令，变1条操作命令的操作。   

AOF的重写是子线程bgrewriteaof完成的，这样避免了阻塞主线程。 

每次执行重写时，主线程fork出后台的bgrewriteaof子进程，并把内存拷贝一份给它。

执行重写过程中，新来的操作命令会记录到它的缓冲区，操作命令同时也会写到重写日志的缓冲区。这样保证数据不会丢失，而且是保持了最新状态。



## RDB 内存快照 Redis database的缩写

既保证可靠性，又在宕机时快速恢复。  
**RDB记录的是某一时刻的数据。**

问题：  
- 拍哪些数据？
- 拍的时候能活动吗？


Redis保存的是全量快照。

生成RDB的两个命令：  
- save  
    - 主线程中执行，会导致阻塞
- bgsave    
    - 创建子进程，专门用于写入RDB文件。默认配置。
    
怎么写快照？
主线程fork出bgsave子进程，与其共享内存。当主线程修改数据时，这块数据会被复制一份，bgsave会把这个副本也写入到RDB中。

多久拍一次合适呢？
- 不能过频繁，磁盘扛不住
- fork也占内存开销。

增量快照，做一次全量，后续增量。

增量如何记录呢？
快照以一定频率执行，中间过程以AOF文件记录。


# 如何提高缓存命中
## 什么叫缓存命中
Redis中有相应的数据，就直接读取Redis，性能非常快。

## 如何提高？
尽量保存热点数据，设置过期时间时加个随机数，避免同时过期影响Redis性能。



# Redis分布式锁
分布式锁Redlock算法：                      
让客户端和多个独立的Redis实例依次请求加锁，如果客户端能和半数以上的实例成功的完成加锁操作，那么就认为获取到分布式的锁了，否则，失败。                 

- 第一步，客户端获取当前时间。                
- 第二步，客户端按顺序依次向N个Redis实例执行加锁操作。 
    - 使用set nx，带上ex、px选项以及客户端的唯一标识，加锁操作要设置超时时间，以防死锁。                   
- 第三步，一旦客户端完成了和所有Redis实例的加锁操作，客户端就要计算整个加锁过程的总耗时。                
    加锁成功条件：             
    - 客户端从超过半数的Redis实例获取到了锁。
    - 客户端获取锁的总耗时没有超过锁的有效时间。
    满足了这两个条件后，重新计算锁的有效时间：锁的最初超时时间减去获取锁总耗时。如果时间不够了，那么可以释放锁。                  
    如果没有满足这两个条件，那么客户端向所有节点发起释放锁操作。                      
    
    
    
    
                    
